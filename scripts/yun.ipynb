{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msympy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EX\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprompt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_prompt, get_task_name, get_task_description\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mresponse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_batch_response\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/Data_augmentation/scripts/response.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_model_batch_response\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m \n",
      "File \u001b[0;32m~/Data_augmentation/scripts/utils.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Completion \u001b[38;5;28;01mas\u001b[39;00m OpenAICompletion\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RateLimitError \u001b[38;5;28;01mas\u001b[39;00m OpenAIRateLimitError\n",
      "File \u001b[0;32m~/miniconda3/envs/data_augmentation/lib/python3.11/site-packages/spacy/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[1;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/data_augmentation/lib/python3.11/site-packages/spacy/errors.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[0;32m~/miniconda3/envs/data_augmentation/lib/python3.11/site-packages/spacy/compat.py:39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcatalogue\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _importlib_metadata \u001b[38;5;28;01mas\u001b[39;00m importlib_metadata  \u001b[38;5;66;03m# type: ignore[no-redef]    # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optimizer  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     41\u001b[0m pickle \u001b[38;5;241m=\u001b[39m pickle\n\u001b[1;32m     42\u001b[0m copy_reg \u001b[38;5;241m=\u001b[39m copy_reg\n",
      "File \u001b[0;32m~/miniconda3/envs/data_augmentation/lib/python3.11/site-packages/thinc/api.py:23\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config, ConfigValidationError, registry\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     configure_normal_init,\n\u001b[1;32m     18\u001b[0m     glorot_uniform_init,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     zero_init,\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     LSTM,\n\u001b[1;32m     25\u001b[0m     CauchySimilarity,\n\u001b[1;32m     26\u001b[0m     ClippedLinear,\n\u001b[1;32m     27\u001b[0m     Dish,\n\u001b[1;32m     28\u001b[0m     Dropout,\n\u001b[1;32m     29\u001b[0m     Embed,\n\u001b[1;32m     30\u001b[0m     Gelu,\n\u001b[1;32m     31\u001b[0m     HardSigmoid,\n\u001b[1;32m     32\u001b[0m     HardSwish,\n\u001b[1;32m     33\u001b[0m     HardSwishMobilenet,\n\u001b[1;32m     34\u001b[0m     HardTanh,\n\u001b[1;32m     35\u001b[0m     HashEmbed,\n\u001b[1;32m     36\u001b[0m     LayerNorm,\n\u001b[1;32m     37\u001b[0m     Linear,\n\u001b[1;32m     38\u001b[0m     Logistic,\n\u001b[1;32m     39\u001b[0m     Maxout,\n\u001b[1;32m     40\u001b[0m     Mish,\n\u001b[1;32m     41\u001b[0m     MultiSoftmax,\n\u001b[1;32m     42\u001b[0m     MXNetWrapper,\n\u001b[1;32m     43\u001b[0m     ParametricAttention,\n\u001b[1;32m     44\u001b[0m     ParametricAttention_v2,\n\u001b[1;32m     45\u001b[0m     PyTorchLSTM,\n\u001b[1;32m     46\u001b[0m     PyTorchRNNWrapper,\n\u001b[1;32m     47\u001b[0m     PyTorchWrapper,\n\u001b[1;32m     48\u001b[0m     PyTorchWrapper_v2,\n\u001b[1;32m     49\u001b[0m     PyTorchWrapper_v3,\n\u001b[1;32m     50\u001b[0m     Relu,\n\u001b[1;32m     51\u001b[0m     ReluK,\n\u001b[1;32m     52\u001b[0m     Sigmoid,\n\u001b[1;32m     53\u001b[0m     Softmax,\n\u001b[1;32m     54\u001b[0m     Softmax_v2,\n\u001b[1;32m     55\u001b[0m     SparseLinear,\n\u001b[1;32m     56\u001b[0m     SparseLinear_v2,\n\u001b[1;32m     57\u001b[0m     Swish,\n\u001b[1;32m     58\u001b[0m     TensorFlowWrapper,\n\u001b[1;32m     59\u001b[0m     TorchScriptWrapper_v1,\n\u001b[1;32m     60\u001b[0m     add,\n\u001b[1;32m     61\u001b[0m     array_getitem,\n\u001b[1;32m     62\u001b[0m     bidirectional,\n\u001b[1;32m     63\u001b[0m     chain,\n\u001b[1;32m     64\u001b[0m     clone,\n\u001b[1;32m     65\u001b[0m     concatenate,\n\u001b[1;32m     66\u001b[0m     expand_window,\n\u001b[1;32m     67\u001b[0m     keras_subclass,\n\u001b[1;32m     68\u001b[0m     list2array,\n\u001b[1;32m     69\u001b[0m     list2padded,\n\u001b[1;32m     70\u001b[0m     list2ragged,\n\u001b[1;32m     71\u001b[0m     map_list,\n\u001b[1;32m     72\u001b[0m     noop,\n\u001b[1;32m     73\u001b[0m     padded2list,\n\u001b[1;32m     74\u001b[0m     premap_ids,\n\u001b[1;32m     75\u001b[0m     pytorch_to_torchscript_wrapper,\n\u001b[1;32m     76\u001b[0m     ragged2list,\n\u001b[1;32m     77\u001b[0m     reduce_first,\n\u001b[1;32m     78\u001b[0m     reduce_last,\n\u001b[1;32m     79\u001b[0m     reduce_max,\n\u001b[1;32m     80\u001b[0m     reduce_mean,\n\u001b[1;32m     81\u001b[0m     reduce_sum,\n\u001b[1;32m     82\u001b[0m     remap_ids,\n\u001b[1;32m     83\u001b[0m     remap_ids_v2,\n\u001b[1;32m     84\u001b[0m     residual,\n\u001b[1;32m     85\u001b[0m     resizable,\n\u001b[1;32m     86\u001b[0m     siamese,\n\u001b[1;32m     87\u001b[0m     sigmoid_activation,\n\u001b[1;32m     88\u001b[0m     softmax_activation,\n\u001b[1;32m     89\u001b[0m     strings2arrays,\n\u001b[1;32m     90\u001b[0m     tuplify,\n\u001b[1;32m     91\u001b[0m     uniqued,\n\u001b[1;32m     92\u001b[0m     with_array,\n\u001b[1;32m     93\u001b[0m     with_array2d,\n\u001b[1;32m     94\u001b[0m     with_cpu,\n\u001b[1;32m     95\u001b[0m     with_debug,\n\u001b[1;32m     96\u001b[0m     with_flatten,\n\u001b[1;32m     97\u001b[0m     with_flatten_v2,\n\u001b[1;32m     98\u001b[0m     with_getitem,\n\u001b[1;32m     99\u001b[0m     with_list,\n\u001b[1;32m    100\u001b[0m     with_nvtx_range,\n\u001b[1;32m    101\u001b[0m     with_padded,\n\u001b[1;32m    102\u001b[0m     with_ragged,\n\u001b[1;32m    103\u001b[0m     with_reshape,\n\u001b[1;32m    104\u001b[0m     with_signpost_interval,\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    107\u001b[0m     CategoricalCrossentropy,\n\u001b[1;32m    108\u001b[0m     CosineDistance,\n\u001b[1;32m    109\u001b[0m     L2Distance,\n\u001b[1;32m    110\u001b[0m     SequenceCategoricalCrossentropy,\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    113\u001b[0m     Model,\n\u001b[1;32m    114\u001b[0m     change_attr_values,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     wrap_model_recursive,\n\u001b[1;32m    119\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/data_augmentation/lib/python3.11/site-packages/thinc/layers/__init__.py:66\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstrings2arrays\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m strings2arrays\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mswish\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Swish\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflowwrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorFlowWrapper, keras_subclass\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorchscriptwrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TorchScriptWrapper_v1, pytorch_to_torchscript_wrapper\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuplify\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tuplify\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1069\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:729\u001b[0m, in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import argparse\n",
    "import re\n",
    "from sympy import EX\n",
    "from prompt import get_prompt, get_task_name, get_task_description\n",
    "from response import get_batch_response\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from find_path import find_path\n",
    "from utils import get_model_batch_response\n",
    "import math\n",
    "import tqdm \n",
    "\n",
    "prompt_t = \"\"\"\n",
    "    I am training a model using RoBERTa + MLP on a task named {task_name}. The task involves {task_description}. \n",
    "    Your task is to identify potential spurious patterns that the model might have learned based on its responses.\n",
    "\n",
    "    I will present you with an instance where the model provided incorrect responses. \n",
    "\n",
    "    Please provide {spurious_num} assumptions of spurious patterns that may have caused the incorrect response. \n",
    "    Each assumption should be followed by {generate_num} verification data points to determine whether the model consistently makes mistakes \n",
    "    due to such a spurious pattern. The verification data should align with the identified spurious patterns. \n",
    "    Having the same pattern does not mean copying the original text and target verbatim; instead, \n",
    "    it should reflect the same pattern at a higher level of abstraction and  \"text\" and \"target\" in the generated should be diverse with various contents and different speaking way, and include spurious patterns.\n",
    "\n",
    "    A spurious pattern refers to a misleading or non-causal feature relationship that the model learns during training, \n",
    "    such as misunderstandings of certain phrases, sentiment words, or entity relations.Be specific in the patterns, such as what words or what relations, but not a general description.\n",
    "\n",
    "    Format your evaluation instances using XML tags. Each <Spurious_i> tag should include:\n",
    "\n",
    "    An assumption of the spurious pattern that the model may have learned.\n",
    "    {generate_num} verification data points, each enclosed in <verification_i> from <verification_1> to <verification_10>, where i is the sequential number of the verification set.\n",
    "    Each <verification_i> should contain the following:\n",
    "\n",
    "       1. <text>: A multi-sentence passage containing the spurious pattern. Generate the sample as long as the incorrect instance in length, at least 100 words in each data with a suitable context.\n",
    "       2. <target>: An entity mentioned in the text.\n",
    "       3. <ground_truth>: The true label for the classification task.\n",
    "    Ensure that the ground truth of the generated data is ascertainably correct. If the correctness of the given instance cannot be determined, leave the field blank.\n",
    "    The incorrect instance is as follows:\n",
    "    {data}\n",
    "    Please output all content completely without omitting or summarizing.\n",
    "    Confirm that the generated data should be diverse to avoid overfitting of the smaller model.\n",
    "    \"\"\"\n",
    "\n",
    "def format_prompt(data,prompt, task,description,spurious_num,generate_num):\n",
    "    # NOTE\n",
    "    # model's label { \"FAVOR\": 0  , \"NONE\": 1 , \"AGAINST\":  2}\n",
    "    # the data is from model's inference\n",
    "    # but that is needed to transform to { \"FAVOR\": 1, \"NONE\": 2, \"AGAINST\": 0}\n",
    "    transform_dict = {\n",
    "        0: 'FAVOR',\n",
    "        1: 'NONE',\n",
    "        2: 'AGAINST'\n",
    "    }\n",
    "    prompts = []\n",
    "    for d in data:\n",
    "        d_ = {\n",
    "            \"input_text\": d[\"input_text\"],\n",
    "            \"target\": d[\"target\"],\n",
    "            \"predicted_label\": transform_dict[d[\"predicted_label\"]],\n",
    "            \"true_label\": transform_dict[d[\"true_label\"]]\n",
    "        }\n",
    "        prompts.append(prompt.format(task_name = task, task_description = description, spurious_num = spurious_num, generate_num = generate_num, data = d_))\n",
    "    return prompts\n",
    "\n",
    "def get_batch_response(model:str, prompts:list, batch = 30,temperature=0, max_token=8192):\n",
    "    if \"llama\" in model:\n",
    "        # meta.llama3-1-8b-instruct-v1:0\n",
    "        response = []\n",
    "        for i in tqdm.tqdm(range(math.ceil(len(prompts)/batch))):\n",
    "            # print(i)\n",
    "            temp_prompt = prompts[i*batch:(i+1)*batch]\n",
    "            try: \n",
    "                r = get_model_batch_response(prompts=temp_prompt,model=model,temperature=temperature,max_new_tokens=max_token)\n",
    "                response = response + r\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        \n",
    "        return response\n",
    "\n",
    "def get_raw_response():\n",
    "    prompt = prompt_t\n",
    "    model = \"meta.llama3-1-70b-instruct-v1:0\"\n",
    "    task = 'task1'\n",
    "    description = \"description1\"\n",
    "    generate_num = 10\n",
    "    spurious_num = 3\n",
    "    with open('../results/baseline/checkpoint-216/log_dev_wrong_test_data.json',\"r\") as f:\n",
    "        data = json.load(f)\n",
    "    prompts = format_prompt(data,prompt,task,description,spurious_num,generate_num)\n",
    "    print(prompts[0])\n",
    "    response = get_batch_response(model,prompts,batch = 1)\n",
    "    return \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "You need to augment the data to four new data for training a student in stance detection. Stance detection aims to identify the authors' attitudes or positions [FAVOR, NONE, AGAINST] towards a specific target such as an entity, a topic.\n",
      "\n",
      "You are given the following JSON data:\n",
      "{'input_text': \"Look, there are issues to be debateed. Do we need as much brick and mortaror public shelf space as we have? I use libraries a lot. I download audible books frequently, but I don't use my local northern NY library system to do it, I use the NY City Library. If I do want a book I locate it on Amazon (since its presentation of the book: description, professional and reader reviews is much better than the libraries) then I order it (on-line) from my local library system. When I get the e-mail notice that the book is ready I finally pay a visit to my library to pick the book up. Using this process I wonder why my library has publically displayed bookshelves at all.\", 'target': 'library', 'true_label': 'AGAINST'}\n",
      "\n",
      "Your task is to generate 4 new XML examples that follow the same structure as the provided JSON. Each new example must have the same elements as the original JSON data.\n",
      "\n",
      "The augmented data are for the directions:\n",
      "1. Mimimized changing some words to change the stance of the given data to other two labels (it would result in two new samples).\n",
      "2. Change the expression of the original sentence, but not change the targe and the label.\n",
      "3. Change the target to another different target, and give the corresonding stance.\n",
      "\n",
      "For each new example:\n",
      "1. The structure of the XML should match the original JSON, with the same elements.\n",
      "2. The format and types (e.g., numbers, strings, lists) should remain consistent with the original data, and the lengths should be similar. Donot make the expression of the stance too straightforward, with an explicit expression of love, like, neutral, or dislike and so on.\n",
      "3. The new XML data should be valid and realistic for the context of the task.\n",
      "4. The ground_truth should be one of [FAVOR,NONE,AGAINST].\n",
      "\n",
      "Please output the generated data in the following XML format, where each element corresponds to a key in the original JSON:\n",
      "\n",
      "```xml\n",
      "<data>\n",
      "    <example_1>\n",
      "        <text>Regulation of corporations has been subverted by corporations. States that incorporate corporations are not equipped to regulate corporations that are rich enough to influence elections, are rich enough to muster a legal team that can bankrupt the state. Money from corporations and their principals cannot be permitted in the political process if democracy is to survive.</text>\n",
      "        <target>company</target>\n",
      "        <ground_truth>AGAINST</ground_truth>\n",
      "    </example_1>\n",
      "    <example_2>\n",
      "        <text>The whole media mess surrounding the royals is a consequence of the promotional fervor with which royal households (aka, public relations experts) developed stage-set performances for the public to devour. Prior to the Victorian era, those elaborate and lethally expensive weddings, coronations, and funerals - and the fairy tales that went along with them - just didn't exist.</text>\n",
      "        <target>flag burning</target>\n",
      "        <ground_truth>NONE</ground_truth>\n",
      "    </example_2>\n",
      "    <example_3>\n",
      "        <text>Two of the main reasons people switch to cannabis from pharmaceuticals and other drugs such as alcohol: less side-effects and less withdrawal: \"\"Over 41% state that they use cannabis as a substitute for alcohol, 36.1% use cannabis as a substitute for illicit substances, and 67.8% use cannabis as a substitute for prescription drugs. The three main reasons cited for cannabis-related substitution are 'less withdrawal' (67.7%), 'fewer side-effects' (60.4%), and 'better symptom management' suggesting that many patients may have already identified cannabis as an effective and potentially safer adjunct or alternative to their prescription drug regimen.\"\" [Lucas et al. Cannabis as a substitute for alcohol and other drugs: A dispensary-based survey of substitution effect in Canadian medical cannabis patients. Addiction Research & Theory. 2013]</text>\n",
      "        <target>marijuana</target>\n",
      "        <ground_truth>FAVOR</ground_truth>\n",
      "    </example_3>\n",
      "    ...\n",
      "</data>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/529 [00:14<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Here are the four new XML examples that follow the same structure as the provided JSON:\n",
      "\n",
      "```xml\n",
      "<data>\n",
      "    <example_1>\n",
      "        <text>I'm a big fan of libraries. I use them frequently to borrow books, attend events, and study. I love how they provide a quiet and comfortable space for people to learn and grow. I also appreciate how they offer free access to resources and information that might be otherwise unavailable to me.</text>\n",
      "        <target>library</target>\n",
      "        <ground_truth>FAVOR</ground_truth>\n",
      "    </example_1>\n",
      "    <example_2>\n",
      "        <text>I'm not sure what the point of libraries is anymore. With the rise of e-books and online resources, I don't see the need for physical bookshelves. I mean, I can just download a book on my phone or laptop and read it wherever I want. I don't need to go to a library to do that.</text>\n",
      "        <target>library</target>\n",
      "        <ground_truth>NONE</ground_truth>\n",
      "    </example_2>\n",
      "    <example_3>\n",
      "        <text>I recently visited my local library and was impressed by the variety of books and resources they had available. The staff was friendly and helpful, and the atmosphere was quiet and conducive to studying. I ended up spending hours there, getting lost in the pages of a great novel.</text>\n",
      "        <target>library</target>\n",
      "        <ground_truth>FAVOR</ground_truth>\n",
      "    </example_4>\n",
      "    <example_4>\n",
      "        <text>I think libraries are a waste of taxpayer money. They're just a relic of the past, a reminder of a time when people didn't have access to the internet and online resources. I mean, what's the point of having a physical building full of books when you can just access everything you need online?</text>\n",
      "        <target>library</target>\n",
      "        <ground_truth>AGAINST</ground_truth>\n",
      "    </example_4>\n",
      "</data>\n",
      "```\n",
      "\n",
      "These examples follow the same structure as the original JSON, with the same elements and consistent formatting. They also meet the requirements for the task, with realistic and valid text, targets, and ground truths.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import argparse\n",
    "import re\n",
    "from sympy import EX\n",
    "from prompt import get_prompt, get_task_name, get_task_description\n",
    "from response import get_batch_response\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from find_path import find_path\n",
    "from utils import get_model_batch_response\n",
    "import math\n",
    "import tqdm \n",
    "\n",
    "prompt_t = \"\"\" \n",
    "You need to augment the data to four new data for training a student in stance detection. Stance detection aims to identify the authors' attitudes or positions [FAVOR, NONE, AGAINST] towards a specific target such as an entity, a topic.\n",
    "\n",
    "You are given the following JSON data:\n",
    "{data}\n",
    "\n",
    "Your task is to generate {k} new XML examples that follow the same structure as the provided JSON. Each new example must have the same elements as the original JSON data.\n",
    "\n",
    "The augmented data are for the directions:\n",
    "1. Minimally alter certain words to shift the stance of the given data to two other labels, resulting in two new samples.\n",
    "2. Modify the wording of the original sentence with a similar sentence length and a similar meaning, without changing the target and the label.\n",
    "3. Shift the focus to a different target while assigning the corresponding stance, ensuring that the sentence structure remains consistent with the original.\n",
    "\n",
    "For each new example:\n",
    "1. The structure of the XML should match the original JSON, with the same elements.\n",
    "2. The format and types (e.g., numbers, strings, lists) should remain consistent with the original data, and the lengths should be similar. Donot make the expression of the stance too straightforward, with an explicit expression of love, like, neutral, or dislike and so on.\n",
    "3. The new XML data should be valid and realistic for the context of the task.\n",
    "4. The ground_truth should be one of [FAVOR,NONE,AGAINST].\n",
    "\n",
    "Please output the generated data in the following XML format, where each element corresponds to a key in the original JSON:\n",
    "\n",
    "```xml\n",
    "<data>\n",
    "    <example_1>\n",
    "        <text>Regulation of corporations has been subverted by corporations. States that incorporate corporations are not equipped to regulate corporations that are rich enough to influence elections, are rich enough to muster a legal team that can bankrupt the state. Money from corporations and their principals cannot be permitted in the political process if democracy is to survive.</text>\n",
    "        <target>company</target>\n",
    "        <ground_truth>AGAINST</ground_truth>\n",
    "    </example_1>\n",
    "    <example_2>\n",
    "        <text>The whole media mess surrounding the royals is a consequence of the promotional fervor with which royal households (aka, public relations experts) developed stage-set performances for the public to devour. Prior to the Victorian era, those elaborate and lethally expensive weddings, coronations, and funerals - and the fairy tales that went along with them - just didn't exist.</text>\n",
    "        <target>flag burning</target>\n",
    "        <ground_truth>NONE</ground_truth>\n",
    "    </example_2>\n",
    "    <example_3>\n",
    "        <text>Two of the main reasons people switch to cannabis from pharmaceuticals and other drugs such as alcohol: less side-effects and less withdrawal: \"\"Over 41% state that they use cannabis as a substitute for alcohol, 36.1% use cannabis as a substitute for illicit substances, and 67.8% use cannabis as a substitute for prescription drugs. The three main reasons cited for cannabis-related substitution are 'less withdrawal' (67.7%), 'fewer side-effects' (60.4%), and 'better symptom management' suggesting that many patients may have already identified cannabis as an effective and potentially safer adjunct or alternative to their prescription drug regimen.\"\" [Lucas et al. Cannabis as a substitute for alcohol and other drugs: A dispensary-based survey of substitution effect in Canadian medical cannabis patients. Addiction Research & Theory. 2013]</text>\n",
    "        <target>marijuana</target>\n",
    "        <ground_truth>FAVOR</ground_truth>\n",
    "    </example_3>\n",
    "    ...\n",
    "</data>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def format_prompt(data,prompt, task,description,spurious_num,generate_num):\n",
    "    # NOTE\n",
    "    # model's label { \"FAVOR\": 0  , \"NONE\": 1 , \"AGAINST\":  2}\n",
    "    # the data is from model's inference\n",
    "    # but that is needed to transform to { \"FAVOR\": 1, \"NONE\": 2, \"AGAINST\": 0}\n",
    "    transform_dict = {\n",
    "        0: 'FAVOR',\n",
    "        1: 'NONE',\n",
    "        2: 'AGAINST'\n",
    "    }\n",
    "    prompts = []\n",
    "    for d in data:\n",
    "        d_ = {\n",
    "            \"input_text\": d[\"input_text\"],\n",
    "            \"target\": d[\"target\"],\n",
    "            \"true_label\": transform_dict[d[\"true_label\"]]\n",
    "        }\n",
    "        prompts.append(prompt_t.format(data = d_,k = 4))\n",
    "    return prompts\n",
    "\n",
    "def get_batch_response(model:str, prompts:list, batch = 30,temperature=0, max_token=8192):\n",
    "    if \"llama\" in model:\n",
    "        # meta.llama3-1-8b-instruct-v1:0\n",
    "        response = []\n",
    "        for i in tqdm.tqdm(range(math.ceil(len(prompts)/batch))):\n",
    "            # print(i)\n",
    "            temp_prompt = prompts[i*batch:(i+1)*batch]\n",
    "            try: \n",
    "                r = get_model_batch_response(prompts=temp_prompt,model=model,temperature=temperature,max_new_tokens=max_token)\n",
    "                response = response + r\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        \n",
    "        return response\n",
    "\n",
    "def get_raw_response():\n",
    "    prompt = prompt_t\n",
    "    model = \"meta.llama3-1-70b-instruct-v1:0\"\n",
    "    task = 'task1'\n",
    "    description = \"description1\"\n",
    "    generate_num = 4\n",
    "    spurious_num = 3\n",
    "    with open('../results/baseline/checkpoint-216/log_dev_wrong_test_data.json',\"r\") as f:\n",
    "        data = json.load(f)\n",
    "    prompts = format_prompt(data,prompt,task,description,spurious_num,generate_num)\n",
    "    print(prompts[0])\n",
    "    response = get_batch_response(model,prompts,batch = 1)\n",
    "    return response\n",
    "\n",
    "r = get_raw_response()\n",
    "\n",
    "print(r[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_augmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
